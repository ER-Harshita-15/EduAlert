{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d136c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk_Predictor2.ipynb - Complete Model Training and Saving\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08bb3e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE STUDENT RISK PREDICTION MODEL\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COMPREHENSIVE STUDENT RISK PREDICTION MODEL\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504788ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac5b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LOADING AND EXPLORING DATA\n",
      "----------------------------------------\n",
      "Dataset shape: (6378, 21)\n",
      "Features: ['Student_ID', 'Hours_Studied', 'Attendance', 'Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities', 'Sleep_Hours', 'Previous_Scores', 'Motivation_Level', 'Internet_Access', 'Tutoring_Sessions', 'Family_Income', 'Teacher_Quality', 'School_Type', 'Peer_Influence', 'Physical_Activity', 'Learning_Disabilities', 'Parental_Education_Level', 'Distance_from_Home', 'Gender', 'Exam_Score']\n",
      "\n",
      "Basic statistics for key numeric features:\n",
      "       Hours_Studied   Attendance  Sleep_Hours  Previous_Scores  \\\n",
      "count    6378.000000  6378.000000  6378.000000      6378.000000   \n",
      "mean       19.977109    80.020853     7.034964        75.066165   \n",
      "std         5.985460    11.550723     1.468033        14.400389   \n",
      "min         1.000000    60.000000     4.000000        50.000000   \n",
      "25%        16.000000    70.000000     6.000000        63.000000   \n",
      "50%        20.000000    80.000000     7.000000        75.000000   \n",
      "75%        24.000000    90.000000     8.000000        88.000000   \n",
      "max        44.000000   100.000000    10.000000       100.000000   \n",
      "\n",
      "       Tutoring_Sessions  Physical_Activity   Exam_Score  \n",
      "count        6378.000000        6378.000000  6378.000000  \n",
      "mean            1.495296           2.972719    67.252117  \n",
      "std             1.233984           1.028926     3.914217  \n",
      "min             0.000000           0.000000    55.000000  \n",
      "25%             1.000000           2.000000    65.000000  \n",
      "50%             1.000000           3.000000    67.000000  \n",
      "75%             2.000000           4.000000    69.000000  \n",
      "max             8.000000           6.000000   101.000000  \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and explore data\n",
    "print(\"\\n1. LOADING AND EXPLORING DATA\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "df = pd.read_csv('../data/StudentPerformanceFactors.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {df.columns.tolist()}\")\n",
    "\n",
    "# Display basic statistics\n",
    "numeric_features = ['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "                   'Tutoring_Sessions', 'Physical_Activity', 'Exam_Score']\n",
    "print(\"\\nBasic statistics for key numeric features:\")\n",
    "print(df[numeric_features].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45a1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_risk_label(df):\n",
    "    \"\"\"\n",
    "    Create risk labels based on multiple weighted factors\n",
    "    This considers poor performance across multiple dimensions\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Academic Performance Risk (40% weight)\n",
    "    exam_low = df['Exam_Score'] < df['Exam_Score'].quantile(0.25)\n",
    "    prev_low = df['Previous_Scores'] < df['Previous_Scores'].quantile(0.25)\n",
    "    academic_risk = (exam_low.astype(int) * 0.6 + prev_low.astype(int) * 0.4)\n",
    "    \n",
    "    # 2. Engagement Risk (25% weight)\n",
    "    attendance_low = df['Attendance'] < df['Attendance'].quantile(0.3)\n",
    "    hours_low = df['Hours_Studied'] < df['Hours_Studied'].quantile(0.3)\n",
    "    engagement_risk = (attendance_low.astype(int) * 0.6 + hours_low.astype(int) * 0.4)\n",
    "    \n",
    "    # 3. Support System Risk (20% weight)\n",
    "    parental_low = df['Parental_Involvement'].str.lower() == 'low'\n",
    "    resources_low = df['Access_to_Resources'].str.lower() == 'low'\n",
    "    support_risk = (parental_low.astype(int) * 0.6 + resources_low.astype(int) * 0.4)\n",
    "    \n",
    "    # 4. Personal Factors Risk (15% weight)\n",
    "    motivation_low = df['Motivation_Level'].str.lower() == 'low'\n",
    "    sleep_poor = (df['Sleep_Hours'] < 6) | (df['Sleep_Hours'] > 9)\n",
    "    peer_negative = df['Peer_Influence'].str.lower() == 'negative'\n",
    "    learning_disability = df['Learning_Disabilities'].str.lower() == 'yes'\n",
    "    personal_risk = (motivation_low.astype(int) * 0.4 + sleep_poor.astype(int) * 0.2 + \n",
    "                    peer_negative.astype(int) * 0.2 + learning_disability.astype(int) * 0.2)\n",
    "    \n",
    "    # Combine all risk factors with weights\n",
    "    composite_risk_score = (academic_risk * 0.40 + engagement_risk * 0.25 + \n",
    "                           support_risk * 0.20 + personal_risk * 0.15)\n",
    "    \n",
    "    # Students in top 30% of risk scores are considered \"at risk\"\n",
    "    risk_threshold = np.percentile(composite_risk_score, 70)\n",
    "    at_risk = (composite_risk_score >= risk_threshold).astype(int)\n",
    "    \n",
    "    return at_risk, composite_risk_score, risk_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cbfbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Distribution:\n",
      "AtRisk\n",
      "0    4441\n",
      "1    1937\n",
      "Name: count, dtype: int64\n",
      "Percentage at risk: 30.4%\n",
      "Risk threshold: 0.290\n"
     ]
    }
   ],
   "source": [
    "# Create risk labels\n",
    "df['AtRisk'], df['RiskScore'], risk_threshold = create_comprehensive_risk_label(df)\n",
    "\n",
    "print(f\"Risk Distribution:\")\n",
    "print(df['AtRisk'].value_counts())\n",
    "print(f\"Percentage at risk: {df['AtRisk'].mean()*100:.1f}%\")\n",
    "print(f\"Risk threshold: {risk_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93aadcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. PREPARING FEATURES FOR MODELING\n",
      "----------------------------------------\n",
      "Features used in modeling (20):\n",
      "   1. Hours_Studied\n",
      "   2. Attendance\n",
      "   3. Parental_Involvement\n",
      "   4. Access_to_Resources\n",
      "   5. Extracurricular_Activities\n",
      "   6. Sleep_Hours\n",
      "   7. Previous_Scores\n",
      "   8. Motivation_Level\n",
      "   9. Internet_Access\n",
      "  10. Tutoring_Sessions\n",
      "  11. Family_Income\n",
      "  12. Teacher_Quality\n",
      "  13. School_Type\n",
      "  14. Peer_Influence\n",
      "  15. Physical_Activity\n",
      "  16. Learning_Disabilities\n",
      "  17. Parental_Education_Level\n",
      "  18. Distance_from_Home\n",
      "  19. Gender\n",
      "  20. Exam_Score\n"
     ]
    }
   ],
   "source": [
    "# 3. Prepare features for modeling\n",
    "print(\"\\n3. PREPARING FEATURES FOR MODELING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Include ALL features except Student_ID and our created risk labels\n",
    "feature_cols = [col for col in df.columns if col not in ['Student_ID', 'AtRisk', 'RiskScore']]\n",
    "X = df[feature_cols].copy()\n",
    "y = df['AtRisk']\n",
    "\n",
    "print(f\"Features used in modeling ({len(feature_cols)}):\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d70982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. ENCODING CATEGORICAL VARIABLES\n",
      "----------------------------------------\n",
      "Categorical features to encode: 13\n",
      "  Parental_Involvement: 3 categories -> ['High' 'Low' 'Medium']\n",
      "  Access_to_Resources: 3 categories -> ['High' 'Low' 'Medium']\n",
      "  Extracurricular_Activities: 2 categories -> ['No' 'Yes']\n",
      "  Motivation_Level: 3 categories -> ['High' 'Low' 'Medium']\n",
      "  Internet_Access: 2 categories -> ['No' 'Yes']\n",
      "  Family_Income: 3 categories -> ['High' 'Low' 'Medium']\n",
      "  Teacher_Quality: 3 categories -> ['High' 'Low' 'Medium']\n",
      "  School_Type: 2 categories -> ['Private' 'Public']\n",
      "  Peer_Influence: 3 categories -> ['Negative' 'Neutral' 'Positive']\n",
      "  Learning_Disabilities: 2 categories -> ['No' 'Yes']\n",
      "  Parental_Education_Level: 3 categories -> ['College' 'High School' 'Postgraduate']\n",
      "  Distance_from_Home: 3 categories -> ['Far' 'Moderate' 'Near']\n",
      "  Gender: 2 categories -> ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "# 4. Encode categorical variables\n",
    "print(\"\\n4. ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "le_dict = {}\n",
    "X_encoded = X.copy()\n",
    "\n",
    "print(f\"Categorical features to encode: {len(cat_cols)}\")\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X[col])\n",
    "    le_dict[col] = le\n",
    "    print(f\"  {col}: {len(le.classes_)} categories -> {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbc3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. FEATURE SCALING\n",
      "----------------------------------------\n",
      "Features scaled: (6378, 20)\n"
     ]
    }
   ],
   "source": [
    "# 5. Feature scaling\n",
    "print(\"\\n5. FEATURE SCALING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "feature_names = X_encoded.columns.tolist()\n",
    "\n",
    "print(f\"Features scaled: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b900dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. CREATING TRAIN/TEST SPLIT\n",
      "----------------------------------------\n",
      "Training set: 5102 samples (30.4% at risk)\n",
      "Test set: 1276 samples (30.4% at risk)\n"
     ]
    }
   ],
   "source": [
    "# 6. Train/test split\n",
    "print(\"\\n6. CREATING TRAIN/TEST SPLIT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({y_train.mean()*100:.1f}% at risk)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({y_test.mean()*100:.1f}% at risk)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009e15ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. TRAINING MODEL WITH HYPERPARAMETER TUNING\n",
      "----------------------------------------\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "\n",
      "Best parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best cross-validation F1 score: 0.931\n"
     ]
    }
   ],
   "source": [
    "# 7. Model training with hyperparameter tuning\n",
    "print(\"\\n7. TRAINING MODEL WITH HYPERPARAMETER TUNING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Grid search for optimal parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Use the best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model evaluation\n",
    "print(\"\\n8. MODEL EVALUATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Cross-validation for model stability\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='f1')\n",
    "print(f\"Cross-validation F1 scores: {[f'{score:.3f}' for score in cv_scores]}\")\n",
    "print(f\"Mean CV F1 score: {cv_scores.mean():.3f} (¬±{cv_scores.std():.3f})\")\n",
    "\n",
    "# Test set evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nTest Set Results:\")\n",
    "print(f\"  Accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"  AUC-ROC: {test_auc:.3f}\")\n",
    "print(f\"  Generalization Gap: {abs(cv_scores.mean() - test_accuracy):.3f}\")\n",
    "\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Feature importance analysis\n",
    "print(\"\\n9. FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "for i, row in feature_importance.head(15).iterrows():\n",
    "    print(f\"  {row['feature']:25} {row['importance']:.4f}\")\n",
    "\n",
    "# 10. Save model and preprocessing components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27763aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save model and preprocessing components\n",
    "print(\"\\n10. SAVING MODEL AND PREPROCESSING COMPONENTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = '../models/student_risk_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = '../models/feature_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save label encoders\n",
    "le_path = '../models/label_encoders.pkl'\n",
    "with open(le_path, 'wb') as f:\n",
    "    pickle.dump(le_dict, f)\n",
    "print(f\"‚úÖ Label encoders saved to: {le_path}\")\n",
    "\n",
    "# Save feature names and other metadata\n",
    "metadata = {\n",
    "    'feature_names': feature_names,\n",
    "    'feature_cols': feature_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'risk_threshold': risk_threshold,\n",
    "    'model_performance': {\n",
    "        'cv_f1_mean': cv_scores.mean(),\n",
    "        'cv_f1_std': cv_scores.std(),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_auc': test_auc\n",
    "    },\n",
    "    'feature_importance': feature_importance.to_dict('records')\n",
    "}\n",
    "\n",
    "metadata_path = '../models/model_metadata.pkl'\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(f\"‚úÖ Metadata saved to: {metadata_path}\")\n",
    "\n",
    "# Save a sample of the original dataframe for testing\n",
    "sample_df = df.sample(n=min(100, len(df)), random_state=42)\n",
    "sample_path = '../models/sample_data.csv'\n",
    "sample_df.to_csv(sample_path, index=False)\n",
    "print(f\"‚úÖ Sample data saved to: {sample_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e806980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Create prediction function for deployment\n",
    "print(\"\\n11. CREATING PREDICTION FUNCTION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def predict_student_risk(student_id, df, model, scaler, le_dict, feature_names, detailed=True):\n",
    "    \"\"\"\n",
    "    Predict risk for a student by ID\n",
    "    \n",
    "    Args:\n",
    "        student_id: Student ID from dataset\n",
    "        df: Original dataframe\n",
    "        model: Trained model\n",
    "        scaler: Fitted StandardScaler\n",
    "        le_dict: Dictionary of fitted LabelEncoders\n",
    "        feature_names: List of feature names\n",
    "        detailed: If True, show detailed analysis\n",
    "    \n",
    "    Returns:\n",
    "        prediction, probability, student_info\n",
    "    \"\"\"\n",
    "    \n",
    "    row = df[df['Student_ID'] == student_id]\n",
    "    if row.empty:\n",
    "        print(f\"Student_ID {student_id} not found.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    student_info = row.iloc[0].to_dict()\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_cols = [col for col in df.columns if col not in ['Student_ID', 'AtRisk', 'RiskScore']]\n",
    "    features = row[feature_cols].copy()\n",
    "    \n",
    "    # Encode categorical features\n",
    "    features_encoded = features.copy()\n",
    "    for col in le_dict.keys():\n",
    "        if col in features_encoded.columns:\n",
    "            features_encoded[col] = le_dict[col].transform(features[col])\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features_encoded)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = model.predict(features_scaled)[0]\n",
    "    prob = model.predict_proba(features_scaled)[0]\n",
    "    \n",
    "    if detailed:\n",
    "        print(f\"\\n\" + \"=\"*40)\n",
    "        print(f\"RISK ASSESSMENT FOR STUDENT ID: {student_id}\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        print(f\"üìä PREDICTION: {'üö® AT RISK' if pred == 1 else '‚úÖ NOT AT RISK'}\")\n",
    "        print(f\"üìà Risk Probability: {prob[1]:.1%}\")\n",
    "        print(f\"üìà Safe Probability: {prob[0]:.1%}\")\n",
    "        \n",
    "        print(f\"\\nüìã STUDENT PROFILE:\")\n",
    "        print(f\"   Exam Score: {student_info['Exam_Score']}\")\n",
    "        print(f\"   Attendance: {student_info['Attendance']}%\")\n",
    "        print(f\"   Hours Studied: {student_info['Hours_Studied']}\")\n",
    "        print(f\"   Previous Scores: {student_info['Previous_Scores']}\")\n",
    "        print(f\"   Motivation Level: {student_info['Motivation_Level']}\")\n",
    "        print(f\"   Parental Involvement: {student_info['Parental_Involvement']}\")\n",
    "        \n",
    "        # Show most influential factors for this prediction\n",
    "        feature_contributions = model.feature_importances_ * features_scaled[0]\n",
    "        top_factors = pd.DataFrame({\n",
    "            'factor': feature_names,\n",
    "            'contribution': np.abs(feature_contributions)\n",
    "        }).sort_values('contribution', ascending=False).head(5)\n",
    "        \n",
    "        print(f\"\\nüîç TOP 5 INFLUENTIAL FACTORS FOR THIS PREDICTION:\")\n",
    "        for _, row in top_factors.iterrows():\n",
    "            print(f\"   {row['factor']:25} {row['contribution']:.4f}\")\n",
    "    \n",
    "    return pred, prob[1], student_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e71ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction function\n",
    "print(\"\\n12. TESTING PREDICTION FUNCTION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Test on a few random students\n",
    "test_students = df['Student_ID'].sample(3, random_state=42).tolist()\n",
    "print(f\"Testing on students: {test_students}\")\n",
    "\n",
    "for student_id in test_students:\n",
    "    predict_student_risk(student_id, df, best_model, scaler, le_dict, feature_names, detailed=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1477b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"‚úÖ Model trained and saved with {test_accuracy:.1%} accuracy\")\n",
    "print(f\"‚úÖ {len(feature_cols)} features used for prediction\")\n",
    "print(f\"‚úÖ {df['AtRisk'].sum()} out of {len(df)} students identified as at-risk\")\n",
    "print(f\"‚úÖ All model components saved to '../models/' directory\")\n",
    "\n",
    "print(f\"\\nModel Files Created:\")\n",
    "print(f\"  - student_risk_model.pkl (main model)\")\n",
    "print(f\"  - feature_scaler.pkl (preprocessing)\")\n",
    "print(f\"  - label_encoders.pkl (categorical encoding)\")\n",
    "print(f\"  - model_metadata.pkl (feature names & performance)\")\n",
    "print(f\"  - sample_data.csv (test data)\")\n",
    "\n",
    "print(f\"\\nüéâ Ready for Streamlit deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
